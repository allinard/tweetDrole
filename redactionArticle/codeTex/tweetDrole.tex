%% Exemple de source LaTeX pour un article soumis à TALN
\documentclass[10pt,a4paper,twoside]{article}

\usepackage{times}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{booktabs}


% faire les \usepackage dont vous avez besoin AVANT le \usepackage{taln2014} 

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% 
\usepackage{taln2014}
\usepackage[frenchb]{babel}
%
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %


% Titre complet
\title{Est-ce que ce Tweet est drôle ? Détection automatique de tweets humoristiques}

\author{Florian Boudin\up{1}\quad Adeline Granet\up{2}\quad Alexis Linard\up{2}\\
  (1) Laboratoire LINA, Université de Nantes, 2 rue de la Houssinière, BP 92208, 44322 Nantes, France \\ 
  (2) Université de Nantes, 2 rue de la Houssinière, BP 92208, 44322 Nantes, France\\ 
  florian.boudin@univ-nantes.fr, \{adeline.granet,alexis.linard\}@etu.univ-nantes.fr \\ 
}

% Titre qui apparait en en-tête (1 ligne maxi)
\fancyhead[CO]{Détection automatique de tweets humoristiques} 
% Auteurs qui apparaissent en en-tête (1 ligne maxi)
\fancyhead[CE]{Florian Boudin, Adeline Granet, Alexis Linard} 


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %

\begin{document}

\maketitle


\resume{
Nous présentons un outil, HTD4F (Humoristic Tweet Detection for French) qui prend en entrée une liste de tweets bruts issus de Tweeter (sans annotation linguistique) et qui fournit en sortie les tweets détectés comme humoristiques. Cet outil a donc comme fonctionnalité de détecter l'humour dans un tweet. HTD4F donne un taux de précision de 14,5\%. Nous présentons l'approche adoptée, la constitution de corpus, et les méthodes de classification utilisées pour la détection de l'humour dans de courts textes bruités en français.
}
\\

\abstract{
We present a tool, HTD4F (Humoristic Tweet Detection for French) wich takes as input a list of raw tweets from Tweeter, and wich provides as output detected tweets as humoristical. This tool aims at detecting humor in a tweet. The precision rate for HTD4F is 14,5\%. Our approach is presented, together with corpus constitution, and classification methods used for detecting humor in short noisy texts written in french.
}
\\

\motsClefs{Twitter, Humour, Détection de tweets humoristiques, Weka, Classification}
{Twitter, Humor, Humoristic Tweet Detection, Weka, Classification}



%%================================================================
\section{Introduction}


De nos jours, il n’y a plus de distinction nette entre la vie réelle et virtuelle. Il existe, chez les internautes, un besoin permanant de tout partager. Leurs succès, leurs échecs, leurs tracas, voir même leurs repas du midi prennent vie sur la toile, et ce sans aucune limite. Les outils les plus propices à cette déferlante d’informations sont les réseaux sociaux. Cet article s'intéresse à Twitter qui est rapidement devenu leader dans ce domaine avec plus de 500 millions d’utilisateurs.

Par son format limité à des publications de 140 caractères (appelé Tweet), Twitter demande aux utilisateurs de faire passer leurs émotions, leurs sentiments et leurs découvertes en étant le plus concis possible. C’est un fait, Twitter est une véritable mine d’informations grâce à la multitude de messages qui s'y trouvent, mais également à tout ce qui gravite autour. Car un tweet peut être retweeté(reposté) par d'autres utilisateurs, contenir des hashtags définissant parfois le thème dominant.  Nous avons choisi de nous intéresser plus particulièrement aux tweets humoristiques.

Notre objectif est de développer un outil capable de détecter automatiquement si un tweet est drôle ou non. Voici un tweet que l’on souhaiterais classer : " Il court, il court le furet \#Contrepeterie".  De toute évidence, celui-ci est drôle car comme le hashtag le mentionne, il s'agit d'une contrepètrie. 

Des approches similaires ont déjà été réalisées dans le domaine anglophone comme \cite{Raz12, Barbosa2010}. Ces approches seront détaillées dans la section \ref{art}. La section \ref{methClass} sera consacrée à la définition de ce qu'est un tweet avec tous les traits qui le caractérisent, ainsi que les méthodes que nous avons utilisées pour réaliser la classification des tweets grâce à l'outil Weka, et les traits que nous avons sélectionnés. La section \ref{corpus} décrira le corpus d'entraînement qui a servi à construire le modèle ainsi que celui de test avec une présentation de l'accord inter-annotateurs utilisé. La section \ref{eval} expliquera en détail la démarche que nous avons suivie avec les résultats obtenus.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Etat de l'art}
\label{art}
Les idées d’exploitations de tweet ne manquent pas du coté anglophone. Celui qui a largement inspiré la méthode présentée ici est \cite{Raz12}.  Dans cet article, Yishay Raz propose une méthode de classification de tweets humoristiques en anglais selon le type de l’humour. Pour cela, il utilise un algorithme semi-supervisé qui prend en entrée des tweets annotés pour produire des ensembles avec des caractéristiques propres au classifieur.  […]

\begin{itemize}
\item Caractéristiques lexicales : les mots appartiennent à des lexiques particuliers, des entités nommées sont présentes, ou bien une ambiguité se pose;
\item Caractéristiques morphologiques : analyse du temps des verbes, les mots existent-ils;
\item Phonologie : les mots sont-ils connus comme homophone;
\item Style : présence de smiley, ponctuation particulière, hashtag.
\end{itemize}
Cette approche est fortement intéressante. Malheureusement, une partie des caractéristiques nécessite d’avoir énormément de ressources de références. En français, il est difficile de trouver un lexique pour les mots vulgaires, du domaine gay, les entités nommées, les homophones, etc. 
L’évaluation de cette méthode a été réalisé en utilisant le site \url{ http://www.funny-tweets.com} pour collecter un ensemble de tweets " drôles " ce qui a permi d’éviter un tri fastidieux à la main pour classer les tweets en drôle ou non. Depuis, ce site ne fonctionne plus. Nous avons donc cherché une alternative pour la collecte de tweets drôles francophones.

L’article de \cite{Barbosa2010} sur la détection automatique de sentiment émis dans les tweets, montre qu’il y a beaucoup de travaux réalisés dans ce sens que se soit à travers des articles de recherche ou bien des sites proposant de la détection de sentiments en temps réels de tweets.  Sa méthode repose sur trois caractéristiques principalement : le POS tagging, la polarité et la syntaxe spécifique du tweet comme les liens, la ponctuation, les émoticônes, ainsi que la casse des mots. 

Une caractéristique commune aux deux articles est l’analyse du style qui n’est pas dépendante des bases de connaissances de la langue et donc exploitable dans notre étude.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Méthode de classification utilisée}
\label{methClass}
\subsection{Le tweet} 
Comme cela a été mentionné plus tôt, Twitter permet de poster de courts messages de 140 caractères. Il y a certaines caractéristiques présentes dans le tweet qui sont intéressantes : l'utilisateur propriétaire qui est indiqué par 20 caractères commençant par le symbole "@"; la mention ReTweeter avec le nom de l'utilisateur d'origine; le hashtag "\#ironie" est un mot clé donnant le thème du tweet; les liens externes vers d'autres sources pour avoir la fin d'une blague par exemple " http://bit.ly/1l4TdOF". Parmi ces caractéristiques, un grand nombre seront exploités pour créer le modèle d'apprentissage comme cela est détaillé à la section suivante \ref{features}.


\subsection{Les traits}
\label{features}
La tâche de classification consiste à séparer en deux classes distinctes les tweets : une classe "Drôle" et "Pas Drôle". Nous avons testé plusieurs algorithmes qui seront détaillés dans la section \ref{methode}
Une méthode d'apprentissage non-supervisé est utilisée prenant en entrée un ensemble de tweets. Ce dernier va fournir différentes caractéristiques pour le classifieur multi-classe. Les caractéristiques étudiées sont de type lexicales, stylistiques et contextuelles. 

\textbf{Caractéristique lexicale}\\
Lexique de mots : il a été construit à partir des tweets du corpus où chaque mot a été racinisé et auquel on a enlevé les mots creux et nettoyé le surplus comme les liens externes.
\vspace{0.5cm}

\textbf{Caractéristique stylistique}
\begin{itemize}
\item La présence de hashtag comme "\#humour": nous avons trouvé que les utilisateurs ajoutaient un "\#humour" ou "\#contrepètrie" pour identifier le thème sous-entendu dans leur message;
\item La présence de smiley content ou pas content au sein du tweet est observé. Par exemple "c'était pas moi ;)", la présence du smiley montre le caractère ironique de la phrase;
\item Le nombre de points d'exclamation est également pris en compte, par exemple dans une même phrase "je suis calme!" et " je suis calme !!!!!!!!!!" n'ont pas la même signification, et donne de l'intensité au message voir même de l'ironie dans notre cas. 
\end{itemize}
\vspace{0.5cm}

\textbf{Caractéristique contextuel}
\begin{itemize}
\item Le nombre de mots dans le tweet;
\item Le nombre de ReTweet;
\item La longueur total du tweet;
\item Si il s'agit d'un retweet.
\end{itemize}
\vspace{0.5cm}

\subsection{Les méthodes utilisés}
\label{methode}
Pour les méthodes de classification que nous avons utilisées dans Weka, nous avons pris le parti de garder certains des paramètres par défaut. \\
\textbf{Naivesbayes}. C'est le modèle probabiliste le plus utilisé. Il met en avant l'indépendance entre chaque caractèéristisques. Il utilise une hypothèse de distribution Gaussienne pour calculer la probabilité pour chaque caractéristique.\\
\textbf{J48} C'est une méthode d'apprentissage par arbre de décision. Un arbre va être construit de façon récursif en séparant les données suivant des tests sur les features définis.  \\
\textbf{MultilayerPerceptron} Le Perceptron multicouche est un classifieur linéaire organisé en plusieurs couches au sein desquelles une information circule de la couche d'entrée vers la couche de sortie uniquement ; chaque couche est constituée d'un nombre variable de neurones, les neurones de la couche de sortie correspondant toujours aux sorties du système.\\
\textbf{DecisionStump} Consiste en un arbre de décision à une seul niveau. C'est un arbre avec une racine immédiatement connectés à ses feuilles. En outre, donne une prédiction sur une valeur d'un seul trait.
\textbf{RandomForest} L'algorithme des forêts d'arbres décisionnels effectue un apprentissage sur de multiples arbres de décision entraînés sur des sous-ensembles de données légèrement différents.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Le corpus}
\label{corpus}
\subsection{Corpus d'entrainement}

% Nous avons pris le parti de créer deux corpus d'entraînement : le premier est équilibré suivant les deux classes recherchées tweets "Drôle" et "Pas Drôle" ; le second a une proportion de 2/5, où les tweets "drôle" sont les moins représentés, car nous avons pu observer que dans la réalité sur la quantité de tweets postés, très peu sont drôles.
Grâce à l'application twitter4j, deux corpus, un de 10 000 tweets et un autre de 15 000 ont été réalisés. Les deux corpus ont été constitués à partir de tweets drôles ou non : le premier est équilibré suivant les deux classes recherchées (tweets "Drôle" et "Pas Drôle") ; le second a une proportion de 2/5, où les tweets "drôle" sont les moins représentés, car nous avons pu observer que dans la réalité sur la quantité de tweets postés, très peu sont drôles. Le tableau suivant montre les statistiques des deux corpus: 

\begin{table}[!h]
\centering
	\begin{tabular}{lrrrr}
	\toprule
	& \multicolumn{2}{c}{Equilibré}  & \multicolumn{2}{c}{Deséquilibré}\\
	\cmidrule(r){2-3} \cmidrule(r){4-5}

	& Tweets Drôle & Tweets Pas Drôles &  Tweets Drôle & Tweets Pas Drôles \\
	\midrule
	 ReTweets & 166 & 1019 &   & \\
	
	 ReTweetés & 2817 & 4009 & & \\
	
	Non ReTweetés & 2000 & 1273 & &\\
	
	Contrepètries & 200 & / & & \\
	Autodérision & 200 & / & & \\
	 \midrule
	Total & 4817 & 5282 & 4785 &  10541 \\
	\bottomrule
	\end{tabular}
\caption{Composition des corpus d'entraînements}
\end{table}


Pour extraire des tweets, il est important de commencer par choisir des comptes tweeter. Ces comptes doivent contenir soit uniquement (ou grande partie puisqu'il est difficile d'être sur) des tweets "drôles" ou des tweets "pas drôles".

Pour les comptes supposés "drôles", nous avons effectué une sélection de 35 comptes. Nous nous sommes basés essentiellement sur le nom de l'utilisateur contenant des mots clés comme " humour " et " blague ". Voici des exemples de comptes que l'on a pu sélectionner "@100\_blagues, @BlaguesCarambar , @BlagueJour", il est facile de supposer que les tweets seront tous à caractères humoristiques et sûrement drôles. D'autres comptes ont été choisi par rapport à leur notoriété. Ils sont connus pour rassembler des tweets " drôles " par leur ironie ou montrant l'autodérision de leur auteur comme sur @viedemerde.

Pour les comptes répertoriant les tweets dits "pas drôles", nous en avons choisi 28. Nous avons supposé que tous les comptes politiques comme " @elysee ", journalistiques comme " @lemondefr,@LesEchos " ne contenaient pas de blagues, car ils sont supposés donner des informations sérieuses. Mais pour diversifier les domaines évoqués dans les tweets, nous avons ajouté des comptes commerciaux comme @m6, @nantesfr ou @conforama.

Ce corpus est utilisé pour entrainer le modèle d'apprentissage pour distiguer si un tweet est drôle ou non mais pas seulement. Il a été utilisé pour créer un lexique de mots caractéristiques des tweets. Pour cela, tous les mots ont été extraits puis racinisés. A cette liste, les mots creux de langue française, soit une liste de 460 mots, ont été retirés. Chaque mot restant constitue une caractéristique, un trait.



\begin{table}[!h]
\centering
	\begin{tabular}{lrr}
	\toprule
	& Equilibré & Déséquilibré \\
	\midrule
	 Après nettoyage & 14574 & 18973 \\
	 Après racinisation & 10168 & 12956 \\
	\bottomrule
	\end{tabular}
\caption{Constitutions des corpus d'entraînements}
\end{table}

\subsection{Corpus de test} 
Pour constituer le corpus de test, nous avons extrait 250 tweets provenant des comptes des humoristes Gad Elmaleh, Florence Foresti et Cyprien (un youtubeur). Nous les avons choisis, car ils sont représentatifs de Twitter c'est-à-dire une grande majorité de tweets sur le quotidien et quelques tweets drôles. Plus que quiconque ils sont plus susceptibles de par leur métier de poster des tweets drôles .

L'ensemble de ces tweets ont été annoté par 3 annotateurs. Chaque tweet a été annoté par deux annotateurs particulièrement, qui devaient indiquer la mention "Drôle" ou "Pas Drôle". Une fois que cela a été réalisé, un accord annotateur a été calculé. Nous avons utilisé le coefficient $\kappa$ de \cite{cohen1960}. Cet accord est utilisable dans notre cas, car nous n'avons que deux annotateurs pour chaque fichier. Et il nous permet de vérifier que le choix des classes n'est pas du au hazard. La table \ref{anno} montre les résultats que nous avons obtenus :

% mettre la formule du kappa et expliquer chaque terme 
\begin{table}[!h]
\centering
	\begin{tabular}{lr}
	\toprule
	 Document & $\kappa$ \\
	\midrule
	  Fichier 1 & 0.978 \\
	  Fichier 2 &  0.967\\
	  Fichier 3 & 0.974  \\
	\bottomrule
	\end{tabular}
\caption{Résultat accords inter-annotateurs}
\label{anno}
\end{table}

%Nous sommes sur un accord inter-annotateurs presque parfait dans notre cas. Mais il ne faut pas oublier que l'humour reste complètement subjectif. Et que notre résultat montre seulement que les annotateurs ont le même humour.
Nous sommes sur un accord inter-annotateurs presque parfait dans notre cas. Cela s'explique simplement. En effet, le calcul se base sur l'ensemble des tweets annotés or sur les 250 tweets annotés seulement moins d'une vingtaine ont été annotés comme "drôle" par au moins un annotateur. Les tweets dit "drôles" sont donc noyés dans la masse. Il est donc important de re-centrer l'accord inter-annotateur sur uniquement les tweets annotés au moins une fois comme "drôle". 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Phase d'évaluation}
\label{eval}
\subsection{Méthodologie}
Nous avons commencé par créer les corpus d'entraînement, de test et la baseline.

Ensuite, nous avons construit les traits qui se basaient sur le corpus, comme le lexique de mots. Avant de créer le fichier contenant les caractéristiques de chaque tweet du corpus d'entraînement.

A l'aide de Weka, nous avons entraîné des modèles grâce aux méthodes de classifieurs cité à la section\ref{methode}. Le but de notre démarche est de trouver des tweets " drôle " à coup sur et non de trouver des tweets "pas drôle" comme étant "drôle". C'est pour cela que sur certaines méthodes nous avons ajouté une matrice de coût. Cette matrice de coût permet de sanctionner lourdement les erreurs de classification d'un tweet "pas drôle" en un tweet "drôle". Nous avons testé la classification avec deux valeurs de matrice : la première avec un poids de 10 à chaque erreur et la seconde avec un poids de 100. Le détail des résultats avec cette matrice est décrite à la section\ref{res}.

Et pour finir, nous avons intégré directement la phase de test sur le corpus de test que nous avions préalablement annoté à la main.

\subsection{Notre baseline}
Nous avons créé un dernier corpus pour représenter notre baseline. Notre réflexion a été la suivante : si un tweet comporte un smiley, il est classé comme "drôle" et dans le cas contraire il sera classé comme "Pas drôle". Nous devons insister sur le fait que nous voulons un système très précis c'est à dire avec une forte précision. Le rappel est peu intéressant. En effet, nous voulons être sur de ne pas classer un tweet "Pas Drôle" comme étant "Drôle" et plutôt que de classer un tweet comme "Pas drôle" alors qu'il était "Drôle", ce qui est moins grave.


\subsection{Mesures d'évaluation}

\subsection{Les résultats}
\label{res}
faire un joli tableau, comparer à une baseline ( mais laquelle ? par exemple  1 smiley = 1 tweet drole mais il faut justifier cette baseline ) 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion et discussion}

De notre expérience, nous en déduisons ceci : pour que les traits qui sont des mots soient exploitables, il faudrait y associer le contexte dans lequel il est sorti. Par exemple, dans le corpus de test, nous avons le tweet suivant "Ceux qui vous disent "j'ai dormi comme un bébé"... n'ont jamais eu de bébé:)" est selon nous "drôle". Le souci est que le mot "bébé" a la même période faisait les gros titre des journaux pour des faits graves. Sauf que sans avoir le contexte, le tweet cité sera classé comme "Pas Drôle" à cause du choix du corpus d'entrainement. L'étude du contexte de chaque tweet pourrait également aider à la recherche de passage ironique. 
[Même mettre un feature numérique plutôt que booléen pour les mots ne garantira pas d'éviter l'ambiguité]


%
%\subsection{Titre de la première sous-partie}
%\begin{itemize}
%\item Une liste à puce 
%\end{itemize}
%\begin{enumerate}
%\item Une liste numérotée
%\end{enumerate}
%
%\begin{table}[!h]
%\centering
%	\begin{tabular}{|c|p{4cm}|}
%	\hline
%	Un tableau&\\
%	\hline
%	&Les cellules ainsi que le tableau sont centrés\\
%	\hline
%	\end{tabular}
%\caption{Un tableau}
%\end{table}
%
%\begin{figure}[htbp] 
%\begin{center} 
%\includegraphics{atala.png}
%\end{center} 
%\caption{Une image comme figure} \label{image} \
%\end{figure}
%
%
%Un texte qui termine par une note de bas de page\footnote{Que voici !}.
%
%Le renvoi à une référence bibliographique : \cite{Bernhard07}, et le renvoie à plusieurs références : \cite{TALN2014,LanglaisPatry07}.
%
%\begin{figure}[htbp] 
%\begin{center} 
%~\\
%~\\
%\framebox[5cm]{étape 1}\\
% ~~~~~~~~ | \\
% ~~~~~~~~ | \\
%\framebox[5cm]{étape 2}\\
%~~~~~~~~ | \\
%~~~~~~~~ | \\
%\framebox[5cm]{étape 3}\\
%~~~~~~~~ | \\
%~~~~~~~~ | \\
%\framebox[5cm]{étape 4}\\
%
%\end{center} 
%\caption{Un schéma comme figure} \label{schema}
%\end{figure}
%
%
%%%================================================================
%
%\subsection{Sous-partie}
%
%etc.
%
%
%\section{TALN 2014 à Marseille}
%
%Organisée par le LPL (Laboratoire Parole et Langage) et le LIF (Laboratoire d’Informatique Fondamentale), la conférence TALN (Traitement Automatique des Langues Naturelles) aura lieu pour son 20ème anniversaire à Marseille (Faculté Saint-Charles, Aix-Marseille Université) du 1er au 4 juillet 2014.
%
%La conférence TALN 2014, qui est organisée sous l’égide de l’ATALA, se tiendra conjointement avec la 16ème édition des Rencontres des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (RECITAL 2014).
%
%La conférence TALN 2014 comprendra des communications orales présentant des travaux de recherche et des prises de position, des communications affichées, des conférences invitées et des démonstrations.
%
%La langue officielle de la conférence est le français. Les communications en anglais sont acceptées pour les participants non francophones.
%
%
%%%================================================================
%\subsection{Types de communications}
%
%Deux formats de communications sont prévus : les articles longs (de 12 à 14 pages) et les articles courts (de 6 à 8 pages).
%
%Les auteurs sont invités à présenter deux types de communications :
%\begin{itemize}
%   \item des articles présentant des travaux de recherche originaux
%   \item des prises de position présentant un point de vue sur l’état des recherches en TALN, fondées sur une solide expérience du domaine
%\end{itemize}
%
%Les articles doivent présenter des travaux originaux, comportant un apport substantiel par rapport à d’autres travaux éventuellement déjà publiés. Les traductions d’articles publiés ailleurs dans une autre langue ne sont pas acceptées.
%
%Les articles longs seront présentés sous forme d’une communication orale, les articles courts sous forme d’un poster.
%
%Les communications pourront porter sur tous les thèmes du TAL.
%
%\subsection{Critères de sélection}
%
%Les soumissions seront examinées par au moins deux spécialistes du domaine. Pour les travaux de recherche, seront considérées en particulier :
%\begin{itemize}
% \item  l’adéquation aux thèmes de la conférence
% \item  l’importance et l’originalité de la contribution
% \item  la correction du contenu scientifique et technique
% \item  la discussion critique des résultats, en particulier par rapport aux autres travaux du domaine
% \item  la situation des travaux dans le contexte de la recherche internationale
% \item  l’organisation et la clarté de la présentation
%\end{itemize}
%
%
%Pour les prises de position, seront privilégiées :
%\begin{itemize}
% \item   la largeur de vue et la prise en compte de l’état de l’art
% \item   l’originalité et l’impact du point de vue présenté
%\end{itemize}
%
%Les articles sélectionnés seront publiés dans les actes de la conférence.
%
%Le comité de programme sélectionnera parmi les communications acceptées un article (prix TALN) pour recommandation à publication (dans une version étendue) dans la revue Traitement Automatique des Langues (revue
%TAL).
%
%
%%%================================================================
%\section*{Remerciements (pas de numéro)}
%
%Paragraphe facultatif
%
%%%================================================================
%%% Note : si l'on préfère éviter de factoriser les crossrefs :
%%% bibtex -min-crossrefs 99 taln-exemple
%%%================================================================
\bibliographystyle{taln2002}
\bibliography{biblio}
%\nocite{TALN2014,LaigneletRioult09,LanglaisPatry07,SeretanWehrli07}

%%================================================================
\end{document}
